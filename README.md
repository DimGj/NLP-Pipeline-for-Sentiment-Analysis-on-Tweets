# ğŸ¦ NLP Pipeline for Sentiment Analysis on Tweets

This project implements a complete **Natural Language Processing (NLP) pipeline** to perform **sentiment analysis** on tweets.  
It was developed as part of the **Data Extraction Methods** university course, in collaboration with **[@Natedrake7](https://github.com/Natedrake7)**.

---

## ğŸ“Œ Features
- ğŸ§¹ **Data preprocessing & cleaning** (tokenization, stopword removal, normalization).  
- ğŸ”  **Vectorization of tweets** using techniques like **TF-IDF** and **Bag-of-Words**.  
- ğŸ¤– **Classification models** for sentiment detection (positive, negative, neutral).  
- ğŸ“Š **Exploratory Data Analysis (EDA)** with visual insights.  
- ğŸ“ **Jupyter Notebook (`final.ipynb`)** for experiments and demonstrations.  
- ğŸš€ **Main script (`main.py`)** to run the full pipeline.  

---

## ğŸ“‚ Project Structure
```

NLP-Pipeline-for-Sentiment-Analysis-on-Tweets/
â”‚â”€â”€ README.md                 # Project documentation
â”‚â”€â”€ CodeScripts/              # Core codebase
â”‚   â”œâ”€â”€ main.py               # Entry point for pipeline execution
â”‚   â”œâ”€â”€ imports.py            # Common imports & constants
â”‚   â”œâ”€â”€ FileHandlers.py       # File input/output utilities
â”‚   â”œâ”€â”€ DataAnalysis.py       # Exploratory Data Analysis scripts
â”‚   â”œâ”€â”€ VectorizationTweets.py# Vectorization (TF-IDF, BoW, etc.)
â”‚   â”œâ”€â”€ Classification.py     # Sentiment classification models
â”‚   â””â”€â”€ final.ipynb           # Jupyter Notebook for experiments
â”‚
â”‚â”€â”€ PickleFiles/              # Serialized models/data
â”‚   â””â”€â”€ a.txt                 # (Placeholder/example pickle file with data)
â”‚
â”‚â”€â”€ TSVFiles/                 # Dataset files
â”‚   â””â”€â”€ a.txt                 # (Placeholder/example tsv file with data)
â”‚

```

---

## âš™ï¸ Requirements

Make sure you have **Python 3.8+** installed.  
This project requires the following Python libraries:

- pandas  
- numpy  
- scikit-learn  
- matplotlib  
- seaborn  
- nltk  
- jupyter (for running the notebook)  

---

## ğŸš€ Usage

- **Run the pipeline from the command line:**  
  ```bash
  python main.py
  ```

- **Open the Jupyter notebook for experiments:**

  ```bash
  jupyter notebook final.ipynb
  ```

---

## ğŸ§© Pipeline Workflow

1. **Load dataset** (tweets from TSV files).
2. **Preprocess data** (cleaning, tokenization, stopword removal).
3. **Vectorize tweets** into numerical features.
4. **Classify sentiments** using ML models.
5. **Generate results** with metrics and visualizations.

---

## ğŸ“Š Example Output

* Sentiment distribution of tweets (positive, negative, neutral).
* Evaluation metrics (accuracy, precision, recall, F1-score).
* Visualizations such as word frequencies or word clouds.



